name: reproduce

on:
  workflow_dispatch:
    inputs:
      demo_ref:
        description: "Git ref in open-telemetry/opentelemetry-demo (tag/branch/SHA)"
        required: false
        default: "main"
      soak_seconds:
        description: "How long to soak (seconds) after health"
        required: false
        default: "180"
  push:
    branches: [main]

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  capture_and_analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout this repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install project
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]


      - name: Sanity (edgetyper import works)
        run: |
          python - <<'PY'
          import sys
          print("sys.path[0:3] = ", sys.path[0:3])
          import edgetyper, importlib
          print("edgetyper module =", edgetyper.__file__)
          PY


      - name: Check Docker & Compose
        run: |
          docker --version
          docker compose version


      - name: Prepare run dir
        run: |
          echo "RUN_DIR=${{ github.workspace }}/runs/${{ github.run_id }}" >> $GITHUB_ENV
          mkdir -p "${{ github.workspace }}/runs/${{ github.run_id }}/collector" site


      - name: Clone OpenTelemetry Demo at requested ref
        env:
          DEMO_REF: ${{ inputs.demo_ref }}
        run: |
          mkdir -p vendor
          git init vendor/opentelemetry-demo
          cd vendor/opentelemetry-demo
          git remote add origin https://github.com/open-telemetry/opentelemetry-demo.git
          git fetch --depth 1 origin "${DEMO_REF}"
          git checkout --detach FETCH_HEAD
          git rev-parse --short HEAD


      - name: Add Collector "extras" (file exporter → OTLP-JSON)
        run: |
          # Detect extras dir (new path with hyphen vs old)
          if [ -d vendor/opentelemetry-demo/src/otel-collector ]; then
            EXTRAS_DIR="vendor/opentelemetry-demo/src/otel-collector"
          elif [ -d vendor/opentelemetry-demo/src/otelcollector ]; then
            EXTRAS_DIR="vendor/opentelemetry-demo/src/otelcollector"
          else
            echo "ERROR: could not find src/otel-collector{,/} directory in the demo repo."
            ls -la vendor/opentelemetry-demo/src || true
            exit 1
          fi
          echo "Using extras dir: $EXTRAS_DIR"

          cat > "$EXTRAS_DIR/otelcol-config-extras.yml" <<'YAML'
          exporters:
            file/edgetyper:
              path: /data/otel-traces.json
          service:
            pipelines:
              traces:
                # Arrays are replaced on merge; keep spanmetrics. See OTel Demo Docker docs.
                exporters: [spanmetrics, file/edgetyper]
          YAML


      - name: Compose override to mount /data into the collector (auto-detect service)
        run: |
          DEMO_DIR="vendor/opentelemetry-demo"
          # Determine collector service name from docker-compose.yml
          if grep -qE '^[[:space:]]{2}otel-collector:' "$DEMO_DIR/docker-compose.yml"; then
            COLLECTOR_SVC="otel-collector"
          elif grep -qE '^[[:space:]]{2}otelcol:' "$DEMO_DIR/docker-compose.yml"; then
            COLLECTOR_SVC="otelcol"
          else
            echo "ERROR: Could not detect collector service name in docker-compose.yml"
            sed -n '1,200p' "$DEMO_DIR/docker-compose.yml" || true
            exit 1
          fi
          echo "Collector service detected: ${COLLECTOR_SVC}"

          cat > "$DEMO_DIR/docker-compose.override.yml" <<YAML
          services:
            ${COLLECTOR_SVC}:
              volumes:
                - ${RUN_DIR}/collector:/data
          YAML


      - name: Bring up OTel Demo (detached)
        working-directory: vendor/opentelemetry-demo
        run: |
          docker compose up --force-recreate --remove-orphans --detach


      - name: Wait for health & soak traffic
        env:
          # Use workflow inputs when present (manual runs), else default to 180s on pushes.
          SOAK_SECONDS: ${{ github.event.inputs.soak_seconds || '180' }}
        run: |
          set -euo pipefail
          echo "Waiting up to 3 minutes for unhealthy/restarting to clear…"
          for i in {1..36}; do
            bad=$(docker ps --format '{{.Names}} {{.Status}}' | grep -E 'unhealthy|restarting' || true)
            if [ -z "$bad" ]; then break; fi
            sleep 5
          done
          # Final default-in-shell in case env var was set to an empty string
          : "${SOAK_SECONDS:=180}"
          echo "Soaking for ${SOAK_SECONDS}s (Locust load generator drives traffic)…"
          sleep "${SOAK_SECONDS}"


      - name: Check that traces file exists
        run: |
          if [ ! -s "${RUN_DIR}/collector/otel-traces.json" ]; then
            echo "No traces captured. Increase soak time or check Collector extras merge."
            exit 2
          fi


      - name: Tear down the demo
        working-directory: vendor/opentelemetry-demo
        run: |
          docker compose down -v


      - name: Show captured trace file
        run: |
          ls -lh "${RUN_DIR}/collector" || true


      - name: Write provenance.json
        env:
          SOAK_SECONDS: ${{ github.event.inputs.soak_seconds || '180' }}
        run: |
          set -euo pipefail
          DEMO_DIR="vendor/opentelemetry-demo"
          DEMO_COMMIT=$(git -C "$DEMO_DIR" rev-parse HEAD 2>/dev/null || echo "unknown")
          DOCKER_VER=$(docker --version | sed 's/,//g')
          COMPOSE_VER=$(docker compose version | sed 's/,//g' || true)
          PY_VER=$(python -c 'import sys; print(".".join(map(str, sys.version_info[:3])))')
          PKG_VER=$(python -c 'import importlib; m=importlib.import_module("edgetyper"); print(getattr(m, "__version__", "dev"))' || echo "dev")
          TRACE="${RUN_DIR}/collector/otel-traces.json"
          SIZE_MB=$(python -c 'import os; p=os.environ.get("TRACE",""); s=os.path.getsize(p) if os.path.exists(p) else 0; print(round(s/1024/1024,2))')
          cat > "${RUN_DIR}/provenance.json" <<JSON
          {
            "target": "otel-demo",
            "demo_ref": "${{ inputs.demo_ref || 'main' }}",
            "demo_commit": "$DEMO_COMMIT",
            "soak_seconds": "${SOAK_SECONDS}",
            "traces_size_mb": "$SIZE_MB",
            "docker_version": "$DOCKER_VER",
            "compose_version": "$COMPOSE_VER",
            "python_version": "$PY_VER",
            "edgetyper_version": "$PKG_VER"
          }
          JSON
          echo "Provenance:" && cat "${RUN_DIR}/provenance.json"


      - name: Extract → Graph → Featurize
        run: |
          edgetyper extract   --input "${RUN_DIR}/collector/otel-traces.json" --out "${RUN_DIR}/spans.parquet"
          edgetyper graph     --spans "${RUN_DIR}/spans.parquet" --out-events "${RUN_DIR}/events.parquet" --out-edges "${RUN_DIR}/edges.parquet"
          edgetyper featurize --events "${RUN_DIR}/events.parquet" --edges "${RUN_DIR}/edges.parquet" --out "${RUN_DIR}/features.parquet"


      - name: Inspect feature columns
        run: |
          python - <<'PY'
          import pandas as pd, os
          fp = os.environ["RUN_DIR"] + "/features.parquet"
          df = pd.read_parquet(fp)
          print("features columns:", list(df.columns))
          print("rows:", len(df))
          PY


      - name: Baselines + Our labels
        run: |
          edgetyper baseline --features "${RUN_DIR}/features.parquet" --mode semconv --out "${RUN_DIR}/pred_semconv.csv"
          edgetyper baseline --features "${RUN_DIR}/features.parquet" --mode timing  --out "${RUN_DIR}/pred_timing.csv"
          edgetyper label    --features "${RUN_DIR}/features.parquet"              --out "${RUN_DIR}/pred_ours.csv"


      - name: Evaluate (full semantics) + Report
        run: |
          # Full-semantics evaluation
          edgetyper eval --name "EdgeTyper (ours)"   --pred "${RUN_DIR}/pred_ours.csv"    --features "${RUN_DIR}/features.parquet" --gt "src/edgetyper/ground_truth.yaml" --out "${RUN_DIR}/metrics_ours.json"
          edgetyper eval --name "Baseline — SemConv" --pred "${RUN_DIR}/pred_semconv.csv" --features "${RUN_DIR}/features.parquet" --gt "src/edgetyper/ground_truth.yaml" --out "${RUN_DIR}/metrics_semconv.json"
          edgetyper eval --name "Baseline — Timing"  --pred "${RUN_DIR}/pred_timing.csv"  --features "${RUN_DIR}/features.parquet" --gt "src/edgetyper/ground_truth.yaml" --out "${RUN_DIR}/metrics_timing.json"
      
          # Robustness: mask SemConv, then re-run all methods (rules-only by default)
          edgetyper featurize --events "${RUN_DIR}/events.parquet" --edges "${RUN_DIR}/edges.parquet" --out "${RUN_DIR}/features_masked.parquet" --mask-semconv
          edgetyper baseline  --features "${RUN_DIR}/features_masked.parquet" --mode semconv --out "${RUN_DIR}/pred_semconv_masked.csv"
          edgetyper baseline  --features "${RUN_DIR}/features_masked.parquet" --mode timing  --out "${RUN_DIR}/pred_timing_masked.csv"
          edgetyper label     --features "${RUN_DIR}/features_masked.parquet"              --out "${RUN_DIR}/pred_ours_masked.csv"   # rules-only (no ML)
      
          edgetyper eval --name "EdgeTyper (ours) — SemConv dropped" \
            --pred "${RUN_DIR}/pred_ours_masked.csv"    --features "${RUN_DIR}/features_masked.parquet" --gt "src/edgetyper/ground_truth.yaml" --out "${RUN_DIR}/metrics_ours_masked.json"
      
          edgetyper eval --name "Baseline — SemConv (dropped)" \
            --pred "${RUN_DIR}/pred_semconv_masked.csv" --features "${RUN_DIR}/features_masked.parquet" --gt "src/edgetyper/ground_truth.yaml" --out "${RUN_DIR}/metrics_semconv_masked.json"
      
          edgetyper eval --name "Baseline — Timing (dropped)" \
            --pred "${RUN_DIR}/pred_timing_masked.csv"  --features "${RUN_DIR}/features_masked.parquet" --gt "src/edgetyper/ground_truth.yaml" --out "${RUN_DIR}/metrics_timing_masked.json"
      
          # Robustness 2: drop Timing, then re-run all methods (rules-only by default)
          edgetyper featurize --events "${RUN_DIR}/events.parquet" --edges "${RUN_DIR}/edges.parquet" \
            --out "${RUN_DIR}/features_masktiming.parquet" --mask-timing
      
          edgetyper baseline --features "${RUN_DIR}/features_masktiming.parquet" --mode semconv \
            --out "${RUN_DIR}/pred_semconv_masktiming.csv"
          edgetyper baseline --features "${RUN_DIR}/features_masktiming.parquet" --mode timing  \
            --out "${RUN_DIR}/pred_timing_masktiming.csv"
          edgetyper label    --features "${RUN_DIR}/features_masktiming.parquet"              \
            --out "${RUN_DIR}/pred_ours_masktiming.csv"   # rules-only (no ML fallback)
      
          edgetyper eval --name "EdgeTyper (ours) — Timing dropped" \
            --pred "${RUN_DIR}/pred_ours_masktiming.csv" \
            --features "${RUN_DIR}/features_masktiming.parquet" \
            --gt "src/edgetyper/ground_truth.yaml" \
            --out "${RUN_DIR}/metrics_ours_masktiming.json"
      
          edgetyper eval --name "Baseline — SemConv (Timing dropped)" \
            --pred "${RUN_DIR}/pred_semconv_masktiming.csv" \
            --features "${RUN_DIR}/features_masktiming.parquet" \
            --gt "src/edgetyper/ground_truth.yaml" \
            --out "${RUN_DIR}/metrics_semconv_masktiming.json"
      
          edgetyper eval --name "Baseline — Timing (Timing dropped)" \
            --pred "${RUN_DIR}/pred_timing_masktiming.csv" \
            --features "${RUN_DIR}/features_masktiming.parquet" \
            --gt "src/edgetyper/ground_truth.yaml" \
            --out "${RUN_DIR}/metrics_timing_masktiming.json"
      
          # Rebuild the report (it will ingest all metrics_*.json)
          edgetyper report --metrics-dir "${RUN_DIR}" --outdir "site" \
            --features "${RUN_DIR}/features.parquet" \
            --gt "src/edgetyper/ground_truth.yaml" \
            --coverage-top 30


      - name: Debug table (matched edges + features)
        run: |
          edgetyper debug --features "${RUN_DIR}/features.parquet" \
            --gt "src/edgetyper/ground_truth.yaml" \
            --pred "${RUN_DIR}/pred_ours.csv" \
            --out "${RUN_DIR}/debug_matched_edges.csv"


      - name: Prepare site assets
        run: |
          mkdir -p site/data
          [ -f "${RUN_DIR}/debug_matched_edges.csv" ] && cp "${RUN_DIR}/debug_matched_edges.csv" site/data/ || true

      
      - name: Build enriched report
        run: |
          edgetyper report \
            --metrics-dir "${RUN_DIR}" \
            --outdir "site" \
            --spans    "${RUN_DIR}/spans.parquet" \
            --events   "${RUN_DIR}/events.parquet" \
            --edges    "${RUN_DIR}/edges.parquet" \
            --features "${RUN_DIR}/features.parquet" \
            --gt       "src/edgetyper/ground_truth.yaml" \
            --coverage-top 30 \
            --provenance "${RUN_DIR}/provenance.json" \
            --assets-dir "site/data"


      - name: Upload results bundle (traces + outputs)
        uses: actions/upload-artifact@v4
        with:
          name: edgetyper-results
          path: |
            runs/${{ github.run_id }}/
            site/

      
      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

  deploy-pages:
    needs: capture_and_analyze
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    environment:
      name: github-pages
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
